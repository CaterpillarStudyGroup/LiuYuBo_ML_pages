<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>10-5 Precision-Recall平衡 - LYBStudy</title>
        <!-- Custom HTML head -->
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="The note of LYB">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="../Introduction.html"><strong aria-hidden="true">1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="../Chapter4/4-0.html"><strong aria-hidden="true">2.</strong> 第四章：K近邻算法</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../Chapter4/4-1.html"><strong aria-hidden="true">2.1.</strong> 4-1 K近邻算法基础</a></li><li class="chapter-item expanded "><a href="../Chapter4/4-2.html"><strong aria-hidden="true">2.2.</strong> 4-2 scikit-learn中的机器学习算法的封装</a></li><li class="chapter-item expanded "><a href="../Chapter4/4-3.html"><strong aria-hidden="true">2.3.</strong> 4-3 训练数据集，测试数据集</a></li><li class="chapter-item expanded "><a href="../Chapter4/4-4.html"><strong aria-hidden="true">2.4.</strong> 4-4 分类准确度</a></li><li class="chapter-item expanded "><a href="../Chapter4/4-5.html"><strong aria-hidden="true">2.5.</strong> 4-5 超参数</a></li><li class="chapter-item expanded "><a href="../Chapter4/4-6.html"><strong aria-hidden="true">2.6.</strong> 4-6 网格搜索</a></li><li class="chapter-item expanded "><a href="../Chapter4/4-7.html"><strong aria-hidden="true">2.7.</strong> 4-7 数据归一化 Feature Scaling</a></li><li class="chapter-item expanded "><a href="../Chapter4/4-8.html"><strong aria-hidden="true">2.8.</strong> 4-8 scikit-learn中的Scaler</a></li><li class="chapter-item expanded "><a href="../Chapter4/4-9.html"><strong aria-hidden="true">2.9.</strong> 4-9 更多有关K近邻算法的思考</a></li></ol></li><li class="chapter-item expanded "><a href="../Chapter5/5-0.html"><strong aria-hidden="true">3.</strong> 第五章：线性回归法</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../Chapter5/5-1.html"><strong aria-hidden="true">3.1.</strong> 5-1 简单线性回归</a></li><li class="chapter-item expanded "><a href="../Chapter5/5-2.html"><strong aria-hidden="true">3.2.</strong> 5-2 最小二乘法</a></li><li class="chapter-item expanded "><a href="../Chapter5/5-3.html"><strong aria-hidden="true">3.3.</strong> 5-3 简单线性回归的实现</a></li><li class="chapter-item expanded "><a href="../Chapter5/5-4.html"><strong aria-hidden="true">3.4.</strong> 5-4 参数计算向量化</a></li><li class="chapter-item expanded "><a href="../Chapter5/5-5.html"><strong aria-hidden="true">3.5.</strong> 5-5 衡量线性回归算法的指标</a></li><li class="chapter-item expanded "><a href="../Chapter5/5-6.html"><strong aria-hidden="true">3.6.</strong> 5-6 最好的衡量线性回归法的指标 R Squared</a></li><li class="chapter-item expanded "><a href="../Chapter5/5-7.html"><strong aria-hidden="true">3.7.</strong> 5-7 简单线性回归和正规方程解</a></li><li class="chapter-item expanded "><a href="../Chapter5/5-8.html"><strong aria-hidden="true">3.8.</strong> 5-8 实现多元线性回归</a></li><li class="chapter-item expanded "><a href="../Chapter5/5-9.html"><strong aria-hidden="true">3.9.</strong> 5-9 scikit-learn中的回归算法</a></li><li class="chapter-item expanded "><a href="../Chapter5/5-10.html"><strong aria-hidden="true">3.10.</strong> 5-10 线性回归的可解释性和更多思考</a></li></ol></li><li class="chapter-item expanded "><a href="../Chapter6/6-1.html"><strong aria-hidden="true">4.</strong> 第六章：梯度下降法</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../Chapter6/6-1.html"><strong aria-hidden="true">4.1.</strong> 6-1 什么是梯度下降法</a></li><li class="chapter-item expanded "><a href="../Chapter6/6-2.html"><strong aria-hidden="true">4.2.</strong> 6-2 模拟实现梯度下降法</a></li><li class="chapter-item expanded "><a href="../Chapter6/6-3.html"><strong aria-hidden="true">4.3.</strong> 6-3 多元线性回归中的梯度下降法</a></li><li class="chapter-item expanded "><a href="../Chapter6/6-4.html"><strong aria-hidden="true">4.4.</strong> 6-4 在线性回归模型中使用梯度下降法</a></li><li class="chapter-item expanded "><a href="../Chapter6/6-5.html"><strong aria-hidden="true">4.5.</strong> 6-5 梯度下降的向量化</a></li><li class="chapter-item expanded "><a href="../Chapter6/6-6.html"><strong aria-hidden="true">4.6.</strong> 6-6 随机梯度下降</a></li><li class="chapter-item expanded "><a href="../Chapter6/6-7.html"><strong aria-hidden="true">4.7.</strong> 6-7 代码实现随机梯度下降</a></li><li class="chapter-item expanded "><a href="../Chapter6/6-8.html"><strong aria-hidden="true">4.8.</strong> 6-8 调试梯度下降法</a></li><li class="chapter-item expanded "><a href="../Chapter6/6-9.html"><strong aria-hidden="true">4.9.</strong> 6-9 有关梯度下降法的更多深入讨论</a></li></ol></li><li class="chapter-item expanded "><a href="../Chapter7/7-0.html"><strong aria-hidden="true">5.</strong> 第七章：PCA与梯度上升法</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../Chapter7/7-1.html"><strong aria-hidden="true">5.1.</strong> 7-1 什么是PCA</a></li><li class="chapter-item expanded "><a href="../Chapter7/7-2.html"><strong aria-hidden="true">5.2.</strong> 7-2 使用梯度上升法求解主成分分析问题</a></li><li class="chapter-item expanded "><a href="../Chapter7/7-3.html"><strong aria-hidden="true">5.3.</strong> 7-3 代码实现主成分分析问题</a></li><li class="chapter-item expanded "><a href="../Chapter7/7-4.html"><strong aria-hidden="true">5.4.</strong> 7-4 求数据的前N个主成分</a></li><li class="chapter-item expanded "><a href="../Chapter7/7-5.html"><strong aria-hidden="true">5.5.</strong> 7-5 高维数据向低维数据映射</a></li><li class="chapter-item expanded "><a href="../Chapter7/7-6.html"><strong aria-hidden="true">5.6.</strong> 7-6 scikit learn中的PCA</a></li><li class="chapter-item expanded "><a href="../Chapter7/7-7.html"><strong aria-hidden="true">5.7.</strong> 7-7 MNIST数据集</a></li><li class="chapter-item expanded "><a href="../Chapter7/7-8.html"><strong aria-hidden="true">5.8.</strong> 7-8 使用PCA降噪</a></li><li class="chapter-item expanded "><a href="../Chapter7/7-9.html"><strong aria-hidden="true">5.9.</strong> 7-9 人脸识别和特征脸(未完成)</a></li></ol></li><li class="chapter-item expanded "><a href="../Chapter8/8-1.html"><strong aria-hidden="true">6.</strong> 第八章：多项式回归与模型泛化</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../Chapter8/8-1.html"><strong aria-hidden="true">6.1.</strong> 8-1 什么是多项式回归</a></li><li class="chapter-item expanded "><a href="../Chapter8/8-2.html"><strong aria-hidden="true">6.2.</strong> 8-2 scikit-learn中的多项式回归和pipeline</a></li><li class="chapter-item expanded "><a href="../Chapter8/8-3.html"><strong aria-hidden="true">6.3.</strong> 8-3 过拟合和欠拟合</a></li><li class="chapter-item expanded "><a href="../Chapter8/8-4.html"><strong aria-hidden="true">6.4.</strong> 8-4 为什么要训练数据集和测试数据集</a></li><li class="chapter-item expanded "><a href="../Chapter8/8-5.html"><strong aria-hidden="true">6.5.</strong> 8-5 学习曲线</a></li><li class="chapter-item expanded "><a href="../Chapter8/8-6.html"><strong aria-hidden="true">6.6.</strong> 8-6 验证数据集与交叉验证</a></li><li class="chapter-item expanded "><a href="../Chapter8/8-7.html"><strong aria-hidden="true">6.7.</strong> 8-7 偏差方差权衡 Bias Variance Trade off</a></li><li class="chapter-item expanded "><a href="../Chapter8/8-8.html"><strong aria-hidden="true">6.8.</strong> 8-8 模型正则化 Regularization</a></li><li class="chapter-item expanded "><a href="../Chapter8/8-9.html"><strong aria-hidden="true">6.9.</strong> 8-9 LASSO Regularization</a></li><li class="chapter-item expanded "><a href="../Chapter8/8-10.html"><strong aria-hidden="true">6.10.</strong> 8-10 L1,L2和弹性网络</a></li></ol></li><li class="chapter-item expanded "><a href="../Chapter9/9-1.html"><strong aria-hidden="true">7.</strong> 第九章：逻辑回归</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../Chapter9/9-1.html"><strong aria-hidden="true">7.1.</strong> 9-1 逻辑回归 Logistic Regression</a></li><li class="chapter-item expanded "><a href="../Chapter9/9-2.html"><strong aria-hidden="true">7.2.</strong> 9-2 逻辑回归的损失函数</a></li><li class="chapter-item expanded "><a href="../Chapter9/9-3.html"><strong aria-hidden="true">7.3.</strong> 9-3 逻辑回归算法损失函数的梯度</a></li><li class="chapter-item expanded "><a href="../Chapter9/9-4.html"><strong aria-hidden="true">7.4.</strong> 9-4 实现逻辑回归算法</a></li><li class="chapter-item expanded "><a href="../Chapter9/9-5.html"><strong aria-hidden="true">7.5.</strong> 9-5 决策边界</a></li><li class="chapter-item expanded "><a href="../Chapter9/9-6.html"><strong aria-hidden="true">7.6.</strong> 9-6 在逻辑回归中使用多项式特征</a></li><li class="chapter-item expanded "><a href="../Chapter9/9-7.html"><strong aria-hidden="true">7.7.</strong> 9-7 scikit-learn中的逻辑回归</a></li><li class="chapter-item expanded "><a href="../Chapter9/9-8.html"><strong aria-hidden="true">7.8.</strong> 9-8 OvR与OvO</a></li></ol></li><li class="chapter-item expanded "><a href="../Chapter10/10-1.html"><strong aria-hidden="true">8.</strong> 第十章：评价分类结果</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../Chapter10/10-1.html"><strong aria-hidden="true">8.1.</strong> 10-1 准确度的陷阱和混淆矩阵</a></li><li class="chapter-item expanded "><a href="../Chapter10/10-2.html"><strong aria-hidden="true">8.2.</strong> 10-2 精确率和召回率</a></li><li class="chapter-item expanded "><a href="../Chapter10/10-3.html"><strong aria-hidden="true">8.3.</strong> 10-3 实现混淆矩阵、精准率、召回率</a></li><li class="chapter-item expanded "><a href="../Chapter10/10-4.html"><strong aria-hidden="true">8.4.</strong> 10-4 F1 score</a></li><li class="chapter-item expanded "><a href="../Chapter10/10-5.html" class="active"><strong aria-hidden="true">8.5.</strong> 10-5 Precision-Recall平衡</a></li><li class="chapter-item expanded "><a href="../Chapter10/10-6.html"><strong aria-hidden="true">8.6.</strong> 10-6 precision-recall曲线</a></li><li class="chapter-item expanded "><a href="../Chapter10/10-7.html"><strong aria-hidden="true">8.7.</strong> 10-7 ROC曲线</a></li><li class="chapter-item expanded "><a href="../Chapter10/10-8.html"><strong aria-hidden="true">8.8.</strong> 10-8 多分类问题中的混淆矩阵</a></li></ol></li><li class="chapter-item expanded "><a href="../Chapter11/11-1.html"><strong aria-hidden="true">9.</strong> 第十一章：支撑向量机 SVM</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../Chapter11/11-1.html"><strong aria-hidden="true">9.1.</strong> 11-1 什么是支撑向量机</a></li><li class="chapter-item expanded "><a href="../Chapter11/11-2.html"><strong aria-hidden="true">9.2.</strong> 11-2 支撑向量机的推导过程</a></li><li class="chapter-item expanded "><a href="../Chapter11/11-3.html"><strong aria-hidden="true">9.3.</strong> 11-3 Soft Margin和SVM的正则化</a></li><li class="chapter-item expanded "><a href="../Chapter11/11-4.html"><strong aria-hidden="true">9.4.</strong> 11-4 scikit-leran中的SVM</a></li><li class="chapter-item expanded "><a href="../Chapter11/11-5.html"><strong aria-hidden="true">9.5.</strong> 11-5 SVM中使用多项式特征</a></li><li class="chapter-item expanded "><a href="../Chapter11/11-6.html"><strong aria-hidden="true">9.6.</strong> 11-6 什么是核函数</a></li><li class="chapter-item expanded "><a href="../Chapter11/11-7.html"><strong aria-hidden="true">9.7.</strong> 11-7 高斯核函数</a></li><li class="chapter-item expanded "><a href="../Chapter11/11-8.html"><strong aria-hidden="true">9.8.</strong> 11-8 scikit-learn中的高斯核函数</a></li><li class="chapter-item expanded "><a href="../Chapter11/11-9.html"><strong aria-hidden="true">9.9.</strong> 11-9 SVM思想解决回归问题</a></li></ol></li><li class="chapter-item expanded "><a href="../Chapter12/12-1.html"><strong aria-hidden="true">10.</strong> 第十二章：决策树</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../Chapter12/12-1.html"><strong aria-hidden="true">10.1.</strong> 12-1 什么是决策树</a></li><li class="chapter-item expanded "><a href="../Chapter12/12-2.html"><strong aria-hidden="true">10.2.</strong> 12-2 信息熵</a></li><li class="chapter-item expanded "><a href="../Chapter12/12-3.html"><strong aria-hidden="true">10.3.</strong> 12-3 使用信息寻找最优划分</a></li><li class="chapter-item expanded "><a href="../Chapter12/12-4.html"><strong aria-hidden="true">10.4.</strong> 12-4 基尼系数</a></li><li class="chapter-item expanded "><a href="../Chapter12/12-5.html"><strong aria-hidden="true">10.5.</strong> 12-5 CART和决策树中的超参数</a></li><li class="chapter-item expanded "><a href="../Chapter12/12-6.html"><strong aria-hidden="true">10.6.</strong> 12-6 决策树解决回归问题</a></li><li class="chapter-item expanded "><a href="../Chapter12/12-7.html"><strong aria-hidden="true">10.7.</strong> 12-7 决策树的局限性</a></li></ol></li><li class="chapter-item expanded "><a href="../Chapter13/13-1.html"><strong aria-hidden="true">11.</strong> 第十三章：集成学习和随机森林</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../Chapter13/13-1.html"><strong aria-hidden="true">11.1.</strong> 13-1 什么是集成学习</a></li><li class="chapter-item expanded "><a href="../Chapter13/13-2.html"><strong aria-hidden="true">11.2.</strong> 13-2 soft voting</a></li><li class="chapter-item expanded "><a href="../Chapter13/13-3.html"><strong aria-hidden="true">11.3.</strong> 13-3 bagging和pasting</a></li><li class="chapter-item expanded "><a href="../Chapter13/13-4.html"><strong aria-hidden="true">11.4.</strong> 13-4 更多关于bagging的讨论</a></li><li class="chapter-item expanded "><a href="../Chapter13/13-5.html"><strong aria-hidden="true">11.5.</strong> 13-5 随机森林和extra-trees</a></li><li class="chapter-item expanded "><a href="../Chapter13/13-6.html"><strong aria-hidden="true">11.6.</strong> 13-6 ada boosting和gradiesnt boosting</a></li><li class="chapter-item expanded "><a href="../Chapter13/13-7.html"><strong aria-hidden="true">11.7.</strong> 13-7 Stacking</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">LYBStudy</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/CaterpillarStudyGroup/LiuYuBo_ML_pages.git" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <p>我们总是希望精准率和召回率这两个指标都尽可能地高。但事实上精准率和召回率是互相矛盾的，我们只能在其中找到一个平衡。</p>
<p>以逻辑回归为例来说明精准率和召回率之间的矛盾关系，以下是逻辑回归的公式：<br />
$$
\begin{aligned}
\hat p = \sigma(\theta^T \cdot x_b) = \frac{1}{1 + \exp(-\theta^T \cdot x_b)}  \
\hat y = 
\begin{cases}
1, &amp;&amp; \hat p \ge 0.5   &amp;&amp;   \theta^T \cdot x_b \ge 0   &amp;&amp;  \text{决策边界}   \
0, &amp;&amp; \hat p \lt 0.5   &amp;&amp;   \theta^T \cdot x_b \lt 0   &amp;&amp;  \theta^T \cdot x_b = 0
\end{cases}
\end{aligned}
$$</p>
<p>在这里决策边界是以0为分界点，如果把0改成一个自定义的threshold，threshold的改变会平移决策边界，从而影响精准率和召回率的结果。<br />
$$
\theta^T \cdot x_b = \text{threshold}
$$</p>
<h1 id="threshold是怎样影响精准率和召回率的"><a class="header" href="#threshold是怎样影响精准率和召回率的">threshold是怎样影响精准率和召回率的</a></h1>
<p><img src="http://windmissing.github.io/images/2019/194.jpg" alt="" /><br />
如图，图中的直线代表决策边界，决策边界右边的样本分类为1，决策边界左边的样本分类为0。图中五角星为实际类别为1的样本，0为实际类别为0的样本。<br />
如果以0为分界点，精准率 = 4/5 = 80，召回率 = 4 / 6 = 0.67<br />
分界点往右移，则精准率提升，召回率降低。<br />
分界点往左移，则精准率下降，召回率提升。</p>
<p>用10-4中的Logic Regression对手写数字分类的例子来说明分界点移动对精准率和召回率的影响</p>
<h1 id="回顾10-4的代码"><a class="header" href="#回顾10-4的代码">回顾10-4的代码</a></h1>
<h2 id="准备数据"><a class="header" href="#准备数据">准备数据</a></h2>
<pre><code class="language-python">import numpy as np
from sklearn import datasets

digits = datasets.load_digits()
X = digits.data
y = digits.target.copy()

y[digits.target==9] = 1
y[digits.target!=9] = 0

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=666)
</code></pre>
<h2 id="训练模型"><a class="header" href="#训练模型">训练模型</a></h2>
<pre><code class="language-python">from sklearn.linear_model import LogisticRegression

log_reg = LogisticRegression()
log_reg.fit(X_train, y_train)
</code></pre>
<h2 id="模型指标"><a class="header" href="#模型指标">模型指标</a></h2>
<pre><code class="language-python">log_reg.score(X_test, y_test)   #  0.9755555555555555

y_predict = log_reg.predict(X_test)

from sklearn.metrics import confusion_matrix
confusion_matrix(y_test, y_predict)   # array([[403,   2], [  9,  36]], dtype=int64)

from sklearn.metrics import precision_score
precision_score(y_test, y_predict)   # 0.9473684210526315

from sklearn.metrics import recall_score
recall_score(y_test, y_predict)   # 0.8

from sklearn.metrics import f1_score
f1_score(y_test, y_predict)   # 0.8674698795180723
</code></pre>
<h1 id="移动logic-regression的分界点"><a class="header" href="#移动logic-regression的分界点">移动Logic Regression的分界点</a></h1>
<h2 id="分析logic-regression当前使用的分界点"><a class="header" href="#分析logic-regression当前使用的分界点">分析Logic Regression当前使用的分界点</a></h2>
<p>上文中提到，通过调整threshold来移动决策边界，但sklearn并没有直接提供这样的接口。自带predict函数都是以0作为threshold的。<br />
但sklearn提供了决策函数，把X_test传进去，得到的是每个样本的score值。<br />
predict函数就是根据样本的score值来判断它的分类结果。</p>
<pre><code class="language-python">log_reg.decision_function(X_test)
</code></pre>
<p>部分输出截图：<br />
<img src="http://windmissing.github.io/images/2019/195.png" alt="" /></p>
<p>例如前10个样本的score值是这样的，那么它们的predict结果都应该为0</p>
<p><code>log_reg.decision_function(X_test)[:10]</code>与<code>log_reg.predict(X_test)[:10]</code>对比：<br />
array([-22.05700117, -33.02940957, -16.21334087, -80.3791447 ,<br />
-48.25125396, -24.54005629, -44.39168773, -25.04292757,<br />
-0.97829292, -19.7174399 ])<br />
array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])</p>
<p>所以可以基于decision_function来移动决策边界。</p>
<pre><code class="language-python">decision_scores = log_reg.decision_function(X_test)
np.min(decision_scores)   # -85.68608522646575
np.max(decision_scores)   # 19.8895858799022
</code></pre>
<h2 id="移动threshold-0-5"><a class="header" href="#移动threshold-0-5">移动threshold: 0-&gt;5</a></h2>
<pre><code class="language-python">y_predict_2 = np.array(decision_scores &gt;= 5, dtype='int')
confusion_matrix(y_test, y_predict_2)   # array([[404,   1], [ 21,  24]], dtype=int64)
precision_score(y_test, y_predict_2)   # 0.96
recall_score(y_test, y_predict_2)   # 0.5333333333333333
</code></pre>
<h2 id="不同分界点的指标对比"><a class="header" href="#不同分界点的指标对比">不同分界点的指标对比</a></h2>
<table><thead><tr><th>threshold</th><th>confusion_matrix</th><th>precision_score</th><th>recall_score</th></tr></thead><tbody>
<tr><td>decision_scores &gt;= 0(default)</td><td>array([[403,   2], [  9,  36]], dtype=int64)</td><td>0.9473684210526315</td><td>0.8</td></tr>
<tr><td>decision_scores &gt;= 5</td><td>array([[404,   1], [ 21,  24]], dtype=int64)</td><td>0.96</td><td>0.5333333333333333</td></tr>
<tr><td>decision_scores &gt;= -5</td><td>array([[390,  15], [  5,  40]], dtype=int64)</td><td>0.7272727272727273</td><td>0.8888888888888888</td></tr>
</tbody></table>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../Chapter10/10-4.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>
                            <a rel="next" href="../Chapter10/10-6.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../Chapter10/10-4.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>
                    <a rel="next" href="../Chapter10/10-6.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>

        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        <script src="../elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../searcher.js" type="text/javascript" charset="utf-8"></script>
        <script src="../clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="../book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
    </body>
</html>
