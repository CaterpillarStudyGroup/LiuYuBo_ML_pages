# Summary

* [Introduction](README.md)
* [第四章：K近邻算法](Chapter4/4-1.md)
   * [4-1 K近邻算法](Chapter4/4-1.md)
   * [4-2 scikit-learn中的机器学习算法的封装](Chapter4/4-2.md)
   * [4-3 训练数据集，测试数据集](Chapter4/4-3.md)
   * [4-4 分类准确度](Chapter4/4-4.md)
   * [4-5 超参数](Chapter4/4-5.md)
   * [4-6 网格搜索](Chapter4/4-6.md)
   * [4-7 数据归一化 Feature Scaling](Chapter4/4-7.md)
   * [4-8 scikit-learn中的Scaler](Chapter4/4-8.md)
   * [4-9 更多有关K近邻算法的思考](Chapter4/4-9.md)
* [第五章：线性回归法](Chapter5/5-1.md)
   * [5-1 简单线性回归](Chapter5/5-1.md)
   * [5-2 最小二乘法](Chapter5/5-2.md)
   * [5-3 简单线性回归的实现](Chapter5/5-3.md)
   * [5-4 参数计算向量化](Chapter5/5-4.md)
   * [5-5 衡量线性回归算法的指标](Chapter5/5-5.md)
   * [5-6 最好的衡量线性回归法的指标 R Squared](Chapter5/5-6.md)
   * [5-7 简单线性回归和正规方程解](Chapter5/5-7.md)
   * [5-8 实现多元线性回归](Chapter5/5-8.md)
   * [5-9 scikit-learn中的回归算法](Chapter5/5-9.md)
   * [5-10 线性回归的可解释性和更多思考](Chapter5/5-10.md)
* [第六章：梯度下降法](Chapter6/6-1.md)
   * [6-1 什么是梯度下降法](Chapter6/6-1.md)
   * [6-2 模拟实现梯度下降法](Chapter6/6-2.md)
   * [6-3 多元线性回归中的梯度下降法](Chapter6/6-3.md)
   * [6-4 在线性回归模型中使用梯度下降法](Chapter6/6-4.md)
   * [6-5 梯度下降的向量化](Chapter6/6-5.md)
   * [6-6 随机梯度下降](Chapter6/6-6.md)
   * [6-7 代码实现随机梯度下降](Chapter6/6-7.md)
   * [6-8 调试梯度下降法](Chapter6/6-8.md)
   * [6-9 有关梯度下降法的更多深入讨论](Chapter6/6-9.md)
   