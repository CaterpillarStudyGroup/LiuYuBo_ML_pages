# 线性回归算法

解决回归问题  
思想简单、实现容易  
许多强大的非线性模型的基础  
结果具有很好的可解释性  
蕴含机器学习中的很多重要思想  

![](http://windmissing.github.io\images\2019\43.png)

**注意1：这里的二维平面图与分类问题的二维平面图不同**  
**在分类问题中，横轴和纵轴都是样本特征，输出标记用颜色表示**  
**在回归问题中，横轴是样本特殊，纵轴是输出标志**

注意2：  
样本特征只有一个，称为简单线性回归  
样本特征有多个，称为多元线性回归

# 简单线性回归

找一条直线，这条直线最大程度地拟合所有的样本特征点
![](http://windmissing.github.io\images\2019\44.png)
![](http://windmissing.github.io\images\2019\45.png)
![](http://windmissing.github.io\images\2019\46.png)

# 一类机器学习算法的基本思路
通过分析问题，确定问题的损失函数(loss function)或效用函数(utility function)  
通过最优化损失函数或效用函数，获得机器学习的模型  
近乎所有的参数学习算法都是这样的套路  
最优化原理  
凸优化  

# 最小化本文中的损失函数

目标：找到$${a}$$和$${b}$$，使用$$\sum_{i=1}^m(y^{(i)-ax^i-b})^2$$尽可能小。  
这是典型的最小二乘法问题：最小化误差的平方  
解得：  

$$
a = \frac{\sum_{i=1}^m(x^{(i)}-\bar x)(y^{(i)}-\bar y)}{\sum_{i=1}^m(x^{(i)}-\bar x)^2}\quad \quad \quad \quad \quad b = \bar y - a\bar x 
$$

